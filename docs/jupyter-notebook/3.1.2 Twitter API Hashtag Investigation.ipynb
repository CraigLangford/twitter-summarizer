{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Twitter API Hashtag Investigation\n",
    "\n",
    "Now that we can successfully log into twitter through tweepy, it may be good to investigate what type of data we will be dealing with. Having followed the trump presidency considerably recently let's investigate what a typical data pull would look like.\n",
    "\n",
    "First lets set up the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keys\n",
    "import tweepy\n",
    "from pprint import pprint\n",
    "consumer_key = keys.CONSUMER_KEY\n",
    "consumer_secret = keys.CONSUMER_SECRET\n",
    "access_token = keys.ACCESS_TOKEN\n",
    "access_token_secret = keys.ACCESS_TOKEN_SECRET\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now lets search for the trending `#trump` tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Gesundheitsgesetz gescheitert: #Trump will sich Steuerreform zuwenden https://t.co/y6VMyH3nNs https://t.co/VejyJKKWcQ\n",
      "2 RT @Bonn1eGreer: #Trump is the kind of guy who hates to lose. Watch his next move. It'll either be a web of lies..or worse\n",
      "#TheCloser\n",
      "https‚Ä¶\n",
      "3 @LToddWood He didn't have the votes just with #Republicans so why are the #Democrats being blamed? #TRUMP made a threat + they didn't flinch\n",
      "4 RT @foreignpolicy77: Lots of pro #Trump saying #obamacare is STILL #Democrats responsibilty. Hows that work? Is redville USA going to doubl‚Ä¶\n",
      "5 @GeorgeTakei #trump expects to get his way w/ women,busines,politics via shame &amp; aggression. We just elected‚Ä¶ https://t.co/V1WgGfXpeU\n",
      "6 Legislating is harder than Republicans thought: BBC News - How disastrous for Trump is healthcare collapse? https://t.co/pljWcu2ZkN #Trump\n",
      "7 RT @foreignpolicy77: Lots of pro #Trump saying #obamacare is STILL #Democrats responsibilty. Hows that work? Is redville USA going to doubl‚Ä¶\n",
      "8 RT @LetKiser: Zivile Opfer in Syrien:#Trump bat um \"Ver√§nderungen bei allen Beschr√§nkungen, die √ºber das V√∂lkerrechts hinausgehen\"\n",
      "https://‚Ä¶\n",
      "9 RT @anna_IIna: Sieg f√ºr #Trump: Moslem-Aktivistin scheitert vor Gericht mit Klage gg das neue Einreiseverbot. Tja, da guckste aber. https:/‚Ä¶\n",
      "10 RT @SupportDonald: #BREAKING: #Liberal #Media Busted Citing FAKE Anti-#Trump POLL Funded By #GeorgeSoros - #FakeNews #Soros \n",
      "#MAGAüá∫üá∏ https:‚Ä¶\n",
      "11 RT @TEN_GOP: Happy 11th Birthday Barron Trump! America‚ô•Ô∏èyou.\n",
      "#MAGA #TrumpTrain #ComeyHearing #Trump https://t.co/qGvgVQTUq3\n",
      "12 RT @fixit_fitz: While everyone was distracted by healthcare #trump managed to pass anti-privacy, anti-epa and anti-civil-rights legislation‚Ä¶\n",
      "13 RT @immigrant4trump: I Fixed @HillaryClinton Tweet üëçüëç #Maga #Trump https://t.co/3m76BrBkmF\n",
      "14 RT @davidicke: Trump has authority to issue revised travel ban, Virginia judge rules https://t.co/BvjRpPeDls #Trump https://t.co/WcBAk9LfNw\n",
      "15 Someone had a lot of money invested in #trump? And a lotta lotta people think Fox, Breitbart and alt-right are prod‚Ä¶ https://t.co/d2K6sB7yBG\n"
     ]
    }
   ],
   "source": [
    "tweets = api.search('#trump')\n",
    "\n",
    "for i, tweet in enumerate(tweets):\n",
    "    print(i+1, tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It looks like the number of tweets is only15 using the tweepy search function. This is due to pagination and each api call can only grab 15 tweets at a time. Looking at the [tweepy Cursor tutorial](https://github.com/tweepy/tweepy/blob/master/docs/cursor_tutorial.rst) reveals that you can request tweets by the page based on the required number of tweets. Let's grab the top 1000 tweets and dump them into a pickle file for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "trump_statuses = [status for status in tweepy.Cursor(api.search, '#trump').items(1000)]\n",
    "pickle.dump(trump_statuses, open('pickle_dumps/trump_statuses.p', 'wb'))\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have our tweets locally we can start tearing them apart. Let's have some fun first and create a word cloud to see what we're dealing with. There seems to be a great option on pip called 'wordcloud' found [here](https://github.com/amueller/word_cloud). We'll install that and see what we can produce!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "trump_statuses = pickle.load(open('pickle_dumps/trump_statuses.p', 'rb'))\n",
    "text_dump = [status.text.strip() for status in trump_statuses]\n",
    "text_dump = ' '.join(text_dump)\n",
    "\n",
    "# We'll make the words into a sillhoute of trump for some fun\n",
    "# Found at https://projects.propublica.org/trump-conflicts/\n",
    "trump_mask = np.array(Image.open(\"wordcloud/trump_mask.png\"))\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add('Trump')\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=trump_mask,\n",
    "               stopwords=stopwords)\n",
    "\n",
    "# generate word cloud\n",
    "wc.generate(text_dump)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(\"images/trump.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are quite a few words that are very relevant to Trump news, however, things like https and co signify that there's some cleaning up to do. Furthermore, some of these tweets may be retweets. Let's see the top tweets based on retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('998 retweets',\n",
      "  '0 favorites.',\n",
      "  'RT @BiologistDan: In last 5 years 7 million gallons of oil have leaked from '\n",
      "  \"3300 pipelines. #Trump doesn't t care, he just approved Keyston‚Ä¶\",\n",
      "  'Has retweeted_status'),\n",
      " ('983 retweets',\n",
      "  '0 favorites.',\n",
      "  'RT @TrumpyLeaks: So much winning! üòÇüòÇüòÇ #obamacare #trump #ryan #trumpcare '\n",
      "  'https://t.co/i2ycZa47wh',\n",
      "  'Has retweeted_status')]\n",
      "[('0 retweets',\n",
      "  '50 favorites.',\n",
      "  'https://t.co/NCpRoUufgS\\n\\n#TRUMPTRAIN #potus #trump',\n",
      "  'No retweeted_status'),\n",
      " ('2 retweets',\n",
      "  '5 favorites.',\n",
      "  'Sign the petition: Tell @SenateDems to protect our consumer protection '\n",
      "  'agency from #Trump  https://t.co/gu9jOzYTZm‚Ä¶ https://t.co/eU85CNLQk0',\n",
      "  'No retweeted_status')]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "trump_statuses = pickle.load(open('pickle_dumps/trump_statuses.p', 'rb'))\n",
    "simplified_statuses = [(str(ts.retweet_count) + \" retweets\", \n",
    "                        str(ts.favorite_count) + \" favorites.\", \n",
    "                        ts.text, \n",
    "                        \"Has retweeted_status\" if 'retweeted_status' in dir(ts) else \"No retweeted_status\")\n",
    "                            for ts in trump_statuses]\n",
    "retweet_sorted = sorted(simplified_statuses, key=lambda x: x[0], reverse=True)\n",
    "favorite_sorted = sorted(simplified_statuses, key=lambda x: x[1], reverse=True)\n",
    "pprint(retweet_sorted[:2])\n",
    "pprint(favorite_sorted[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looking at the above tweets a few things immediately stick out.\n",
    "\n",
    "* Many tweets are truncated (starting with https://t.co) inside the tweets. This explains why https and co were some of the larger words in the map.\n",
    "* Some tweets are truncated, ending with elipses. \n",
    "* Retweets begin with RT, which was one of the other larger words in the word map.\n",
    "* If a tweet is retweeted it will have a retweeted_status\n",
    "\n",
    "Let's investigate how many of these tweets are not retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total tweets: 1000\n",
      "Number of non-retweets: 374\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total tweets:\", len(retweet_statuses))\n",
    "non_retweeted = [ts for ts in trump_statuses if 'retweeted_status' not in dir(ts)]\n",
    "print(\"Number of non-retweets:\", len(non_retweeted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Alright then, looks like there's only 374 original tweets. That's a lot of retweets, and in many cases these will end with ellipses. Let's try to convert these retweets to the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('998 retweets',\n",
      "  '721 favorites.',\n",
      "  'In last 5 years 7 million gallons of oil have leaked from 3300 pipelines. '\n",
      "  \"#Trump doesn't t care, he just approved K‚Ä¶ https://t.co/URMKJNrbpV\",\n",
      "  'Truncated'),\n",
      " ('983 retweets',\n",
      "  '1549 favorites.',\n",
      "  'So much winning! üòÇüòÇüòÇ #obamacare #trump #ryan #trumpcare '\n",
      "  'https://t.co/i2ycZa47wh',\n",
      "  'Not truncated')]\n",
      "[('928 retweets',\n",
      "  '993 favorites.',\n",
      "  '#Trump Trashers Mocked The Literal Meaning Of The #Obama #Wiretap Tweet \\n'\n",
      "  '\\n'\n",
      "  'While Concealing That #Obama Did Conduct‚Ä¶ https://t.co/hEEqxz9tTR',\n",
      "  'Truncated'),\n",
      " ('50 retweets',\n",
      "  '96 favorites.',\n",
      "  'Today marks the longest time a Russian spy has been President of the United '\n",
      "  'States. \\n'\n",
      "  '\\n'\n",
      "  '#TRUMP \\n'\n",
      "  '#trumprussia',\n",
      "  'Not truncated')]\n"
     ]
    }
   ],
   "source": [
    "original_tweets = [t.retweeted_status  if 'retweeted_status' in dir(t) else t\n",
    "                       for t in trump_statuses]\n",
    "simplified_original_statuses = [(str(ts.retweet_count) + \" retweets\", \n",
    "                                 str(ts.favorite_count) + \" favorites.\", \n",
    "                                 ts.text, \n",
    "                                 \"Truncated\" if ts.truncated else \"Not truncated\")\n",
    "                                     for ts in original_tweets]\n",
    "retweet_sorted = sorted(simplified_original_statuses, key=lambda x: x[0], reverse=True)\n",
    "favorite_sorted = sorted(simplified_original_statuses, key=lambda x: x[1], reverse=True)\n",
    "pprint(retweet_sorted[:2])\n",
    "pprint(favorite_sorted[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It looks like the tweets are still truncated, followed by a link to the original tweet. This is to keep the tweet under 140 characters, as per Twitter's rules. To fix this we can try using tweet_mode=extended [from the documentation](https://dev.twitter.com/overview/api/upcoming-changes-to-tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated tweet message: #Trump #Maga #Trump2020 #MakeAmericaGreatAgain #FuckLiberal #FuckTheLeft #Sshumer #NancyPelosi just bigger assholes‚Ä¶ https://t.co/BvW3HUZJG3\n",
      "Full tweet message: #Trump #Maga #Trump2020 #MakeAmericaGreatAgain #FuckLiberal #FuckTheLeft #Sshumer #NancyPelosi just bigger assholes driving America Down https://t.co/1ywjyUzHNE\n",
      "['author', 'contributors', 'coordinates', 'created_at', 'destroy', 'display_text_range', 'entities', 'favorite', 'favorite_count', 'favorited', 'full_text', 'geo', 'id', 'id_str', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status', 'lang', 'parse', 'parse_list', 'place', 'possibly_sensitive', 'possibly_sensitive_appealable', 'quoted_status', 'quoted_status_id', 'quoted_status_id_str', 'retweet', 'retweet_count', 'retweeted', 'retweets', 'source', 'source_url', 'truncated', 'user']\n"
     ]
    }
   ],
   "source": [
    "for tweet in original_tweets:\n",
    "    if tweet.truncated:\n",
    "        truncated_tweet = tweet\n",
    "        break\n",
    "print(\"Truncated tweet message:\", truncated_tweet.text)\n",
    "full_text_status = api.get_status(truncated_tweet.id, tweet_mode='extended')\n",
    "print(\"Full tweet message:\", full_text_status.full_text)\n",
    "print([s for s in dir(full_text_status) if not s.startswith('_')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perfect! Now we can have full, non-truncated tweets. Let's obtain 1000 full tweets this time and remove any truncation. We'll also filter for english only tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "full_trump_statuses = [status for status in tweepy.Cursor(api.search, '#trump', tweet_mode='extended', languages=[\"en\"]).items(1000)]\n",
    "pickle.dump(full_trump_statuses, open('pickle_dumps/full_trump_statuses.p', 'wb'))\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's load up our tweets and ensure they all contain the 'full_text' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url free: ['#Trump agenda will.. |#GOP #Potus #MakeAmericaGreatAgain #TrumpPolls @realDonaldTrump #TrumpTrain', '#Trump plays 3-D chess- World & GOP/DEM #establishment checkers. Next move- watch! #Throwback #BenGarrison Cartoon  ', \"Don't reckon much to @BBCNews  #Trump tribute act..... \"]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "\n",
    "# Get all tweets\n",
    "full_trump_statuses = pickle.load(open('pickle_dumps/full_trump_statuses.p', 'rb'))\n",
    "# Convert retweets to original tweet\n",
    "original_full_tweets = [t.retweeted_status  if 'retweeted_status' in dir(t) else t\n",
    "                           for t in full_trump_statuses]\n",
    "\n",
    "# Clean tweetss\n",
    "used_tweets = set()\n",
    "full_tweet_text = []\n",
    "for tweet in original_full_tweets:\n",
    "    if tweet.id not in used_tweets:\n",
    "        used_tweets.add(tweet.id)\n",
    "        # Obtain text and remove urls\n",
    "        cleaned_tweet = re.sub(\"http\\S+\", \"\", tweet.full_text)\n",
    "        full_tweet_text.append(cleaned_tweet)\n",
    "\n",
    "print(\"Url free:\", full_tweet_text[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now have 1000 original tweets without any urls! Let's try to create another wordmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "cleaner_text_dump = ' '.join(url_free_text)\n",
    "\n",
    "# We'll make the words into a sillhoute of trump for some fun\n",
    "# Found at https://projects.propublica.org/trump-conflicts/\n",
    "trump_mask = np.array(Image.open(\"wordcloud/trump_mask.png\"))\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add('Trump')\n",
    "stopwords.add('amp')\n",
    "stopwords.add('rt')\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=trump_mask,\n",
    "               stopwords=stopwords)\n",
    "\n",
    "# generate word cloud\n",
    "wc.generate(cleaner_text_dump)\n",
    "\n",
    "# store to file\n",
    "wc.to_file(\"images/trump_url_free.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that the wordcloud is saved, let's see what we have.\n",
    "<img src=\"images/trump_url_free.png\" alt=\"Trump Wordcloud\" width=799 height=416>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now it appears we have many key hashtags such as MAGA (make America great again), Russia (many ties with Trump and Russia at the moment, March 27th) and various other related key words. Of course, if you run the code above and generate your own image you'll create a word cloud entirely your own! Now that we gathered the keywords from the tweets, it's time to begin the (much more difficult) task of finding the key **points** that are found in these tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
